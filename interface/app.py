import streamlit as st
import pandas as pd
from kafka import KafkaProducer
import json
import time
import os
import uuid
import psycopg2
from psycopg2.extras import RealDictCursor


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Kafka
KAFKA_CONFIG = {
    "bootstrap_servers": os.getenv("KAFKA_BROKERS", "kafka:9092"),
    "topic": os.getenv("KAFKA_TOPIC", "transactions")
}

def load_file(uploaded_file):
    """–ó–∞–≥—Ä—É–∑–∫–∞ CSV —Ñ–∞–π–ª–∞ –≤ DataFrame"""
    try:
        return pd.read_csv(uploaded_file)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")
        return None

def send_to_kafka(df, topic, bootstrap_servers):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Kafka —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º ID —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
    try:
        producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode("utf-8"),
            security_protocol="PLAINTEXT"
        )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID –¥–ª—è –≤—Å–µ—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        df['transaction_id'] = [str(uuid.uuid4()) for _ in range(len(df))]
        
        progress_bar = st.progress(0)
        total_rows = len(df)
        
        for idx, row in df.iterrows():
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤–º–µ—Å—Ç–µ —Å ID
            producer.send(
                topic, 
                value={
                    "transaction_id": row['transaction_id'],
                    "data": row.drop('transaction_id').to_dict()
                }
            )
            progress_bar.progress((idx + 1) / total_rows)
            time.sleep(0.01)
            
        producer.flush()
     
        return True
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
        return False

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = {}

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.title("üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Kafka")

# –ë–ª–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
uploaded_file = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏",
    type=["csv"]
)

if uploaded_file and uploaded_file.name not in st.session_state.uploaded_files:
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    st.session_state.uploaded_files[uploaded_file.name] = {
        "status": "–ó–∞–≥—Ä—É–∂–µ–Ω",
        "df": load_file(uploaded_file)
    }
    st.success(f"–§–∞–π–ª {uploaded_file.name} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")

# –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
if st.session_state.uploaded_files:
    st.subheader("üóÇ –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
    
    for file_name, file_data in st.session_state.uploaded_files.items():
        cols = st.columns([4, 2, 2])
        
        with cols[0]:
            st.markdown(f"**–§–∞–π–ª:** `{file_name}`")
            st.markdown(f"**–°—Ç–∞—Ç—É—Å:** `{file_data['status']}`")
        
        with cols[2]:
            if st.button(f"–û—Ç–ø—Ä–∞–≤–∏—Ç—å {file_name}", key=f"send_{file_name}"):
                if file_data["df"] is not None:
                    with st.spinner("–û—Ç–ø—Ä–∞–≤–∫–∞..."):
                        success = send_to_kafka(
                            file_data["df"],
                            KAFKA_CONFIG["topic"],
                            KAFKA_CONFIG["bootstrap_servers"]
                        )
                        if success:
                            st.session_state.uploaded_files[file_name]["status"] = "–û—Ç–ø—Ä–∞–≤–ª–µ–Ω"
                            st.rerun()
                else:
                    st.error("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")



st.markdown("---")
st.title("üìä –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∫–æ—Ä–∏–Ω–≥–∞")

if st.button("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"):
    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ
        conn = psycopg2.connect(
            host=os.getenv("POSTGRES_HOST", "postgres"),
            dbname=os.getenv("POSTGRES_DB", "scores_db"),
            user=os.getenv("POSTGRES_USER", "user"),
            password=os.getenv("POSTGRES_PASSWORD", "password")
        )
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        # –ü–æ–ª—É—á–∞–µ–º 10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ñ—Ä–æ–¥–æ–≤—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        cursor.execute("""
            SELECT transaction_id, score, fraud_flag, created_at 
            FROM scores 
            WHERE fraud_flag = 1 
            ORDER BY created_at DESC 
            LIMIT 10;
        """)
        fraud_results = cursor.fetchall()

        st.subheader("üö® –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ñ—Ä–æ–¥–æ–≤—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
        if fraud_results:
            df_fraud = pd.DataFrame(fraud_results)
            st.dataframe(df_fraud)
        else:
            st.info("–§—Ä–æ–¥–æ–≤—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        cursor.execute("""
            SELECT score 
            FROM scores 
            ORDER BY created_at DESC 
            LIMIT 100;
        """)
        all_scores = cursor.fetchall()

        if all_scores:
            df_scores = pd.DataFrame(all_scores)
            st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–∏–Ω–≥–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)")
            st.bar_chart(df_scores["score"])
        else:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã.")

        cursor.close()
        conn.close()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
